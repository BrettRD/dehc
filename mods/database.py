'''The module containing objects that manage the CouchDB database.'''

import base64
import io
import json
import random

from ibmcloudant import CouchDbSessionAuthenticator
from ibmcloudant.cloudant_v1 import CloudantV1, BulkDocs, Document, IndexDefinition, IndexField
from PIL import Image

import mods.log as ml


# ----------------------------------------------------------------------------

class Database:
    '''A class which enables communication with a CouchDB database.
    
    This class is application agnostic and only performs basic operations. 
    For helper methods specific to the DEHC application, use the DEHCDatabase 
    class down below.
    
    client: The Cloudant-CouchDB client object.
    index_cache: Cache of indexes that have been created.
    logger: The logger object used for logging.
    '''

    def __init__(self, *, config: str, level: str = "NOTSET"):
        '''Constructs a Database object.
        
        config: Path to .json file containing database server credentials.
        level: Minimum level of logging messages to report; "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL", "NONE".
        '''
        self.logger = ml.get("Database", level=level)
        self.logger.debug("Database object instantiated")
        with open(config, "r") as f:
            self.data = json.loads(f.read())
        auth = CouchDbSessionAuthenticator(username=self.data['user'], password=self.data['pass'])
        self.client = CloudantV1(authenticator=auth)
        self.client.set_service_url(self.data['url'])
        self.logger.debug(f"Connection to {self.data['url']} established")
        self.index_cache = {}


    def database_create(self, dbname: str):
        '''Creates a new database.
        
        dbname: Name of the database to create.
        '''
        self.client.put_database(db=dbname)
        self.logger.debug(f"Created database {dbname}")


    def database_delete(self, dbname: str):
        '''Deletes an existing database.
        
        dbname: Name of the database to delete.
        '''
        self.client.delete_database(db=dbname)
        self.logger.debug(f"Deleted database {dbname}")


    def database_exists(self, dbname: str):
        '''Returns whether or not a database exists.
        
        dbname: Name of the database to check.
        '''
        try:
            response = self.client.get_database_information(db=dbname).get_status_code()
            if response == 200:
                self.logger.debug(f"Database {dbname} exists")
                return True
        except:
            pass
        self.logger.debug(f"Database {dbname} does not exist")
        return False


    def database_list(self):
        '''Returns a list of active databases.'''
        res = self.client.get_all_dbs().get_result()
        self.logger.debug(f"Databases listed")
        return res


    def document_create(self, dbname: str, doc: dict, id: str = None):
        '''Creates a new document, returning its id.
        
        dbname: Name of database to create document in.
        doc: The contents of the document.
        id: The UUID of the document. If omitted, one is generated by CouchDB.
        '''
        new_doc = Document(id=self.id_get()[0], **doc) if id == None else Document(id=id, **doc)
        res = self.client.post_document(db=dbname, document=new_doc).get_result()
        id = res['id']
        self.logger.debug(f"Created document {dbname} {id}")
        return id


    def document_delete(self, dbname: str, id: str, lazy: bool = False):
        '''Deletes an existing document.
        
        dbname: Name of database to delete document in.
        id: The UUID of document to delete.
        lazy: If true, won't error if document doesn't exist.
        '''
        if lazy == False or self.document_exists(dbname=dbname, id=id) == True:
            doc = self.client.get_document(db=dbname, doc_id=id).get_result()
            if id.startswith('_design/'):
                _, ddoc = id.split('_design/')
                self.client.delete_design_document(db=dbname, ddoc=ddoc, rev=doc["_rev"])
            else:
                self.client.delete_document(db=dbname, doc_id=id, rev=doc["_rev"])
            self.logger.debug(f"Deleted document {dbname} {id}")
        else:
            self.logger.debug(f"Could not lazy delete document {dbname} {id}")


    def document_edit(self, dbname: str, doc: dict, id: str, lazy: bool = False):
        '''Edits an existing document.
        
        dbname: Name of database to edit document in.
        doc: Fields and values to be edited.
        id: The UUID of the document to edit.
        lazy: If true, won't error if document doesn't exist.
        '''
        if lazy == False or self.document_exists(dbname=dbname, id=id) == True:
            remote_doc = self.client.get_document(db=dbname, doc_id=id).get_result()
            remote_doc.update(doc)
            self.client.post_document(db=dbname, document=remote_doc)
            self.logger.debug(f"Edited document {dbname} {id}")
        else:
            self.logger.debug(f"Could not lazy edit document {dbname} {id}")


    def document_exists(self, dbname: str, id: str):
        '''Returns whether or not a document exists.
        
        dbname: Name of database to look in.
        id: The UUID of document to look for.
        '''
        try:
            response = self.client.head_document(db=dbname, doc_id=id).get_status_code()
            if response == 200:
                self.logger.debug(f"Document {dbname} {id} exists")
                return True
        except:
            pass
        self.logger.debug(f"Document {dbname} {id} does not exist")
        return False


    def document_get(self, dbname: str, id: str, lazy: bool = False):
        '''Retrieves a document from a database and returns it.
        
        dbname: Name of database to fetch from.
        id: The UUID of document to fetch.
        lazy: If true, won't error if document doesn't exist.
        '''
        if lazy == False or self.document_exists(dbname=dbname, id=id) == True:
            remote_doc = self.client.get_document(db=dbname, doc_id=id).get_result()
            self.logger.debug(f"Fetched document {dbname} {id}")
        else:
            remote_doc = {}
            self.logger.debug(f"Could not fetch document {dbname} {id}")
        return remote_doc


    def documents_create(self, dbname: str, docs: list, ids: list):
        '''Creates multiple documents at once, returning their ids.
        
        dbname: Name of database to create documents in.
        doc: A list of the contents of each document.
        ids: A list of UUIDs of the documents. If omitted, they are generated by CouchDB.
        '''
        doc_list = []
        if ids == None:
            for doc in docs:
                doc = Document(id=self.id_get()[0], **doc)
                doc_list.append(doc)
        else:
            for index, doc in enumerate(docs):
                doc = Document(id=ids[index], **doc)
                doc_list.append(doc)

        doc_list = BulkDocs(docs=doc_list)
        res = self.client.post_bulk_docs(db=dbname, bulk_docs=doc_list).get_result()
        ids = []
        for re in res:
            id = re['id']
            self.logger.debug(f"Bulk created document {dbname} {id}")
            ids.append(id)
        self.logger.debug(f"Finished bulk creating {len(ids)} documents")
        return ids


    def documents_delete(self, dbname: str, ids: str, lazy: bool = False):
        '''Deletes multiple documents at once.
        
        dbname: Name of database to delete documents in.
        ids: The UUIDs of the documents to delete.
        lazy: If true, won't error if any documents doesn't exist.
        '''
        remote_docs = self.client.post_all_docs(db=dbname, limit=len(ids), keys=ids).get_result()['rows']
        for remote_doc in remote_docs:
            id = remote_doc["key"]
            if lazy == False or self.document_exists(dbname=dbname, id=id) == True:
                rev = remote_doc["value"]["rev"]
                if id.startswith("_design/"):
                    _, ddoc = id.split("_design/")
                    self.client.delete_design_document(db=dbname, ddoc=ddoc, rev=rev)
                else:
                    self.client.delete_document(db=dbname, doc_id=id, rev=rev)
                self.logger.debug(f"Bulk deleted document {dbname} {id}")
            else:
                self.logger.debug(f"Could not bulk lazy delete document {dbname} {id}")
        self.logger.debug(f"Finished bulk deleting {len(ids)} documents")


    def documents_edit(self, dbname: str, docs: list, ids: list, lazy: bool = False):
        '''Edits multiple documents at once, returning a list of id and rev numbers. 
        
        dbname: Name of database to edit documents in.
        docs: Lists of fields and values to be edited.
        ids:  List of IDs of documents being edited.
        lazy: If true, won't error if any documents doesn't exist.
        '''
        remote_docs = self.client.post_all_docs(db=dbname, include_docs=True, limit=len(ids), keys=ids).get_result()['rows']
        doc_list = []
        for remote_doc in remote_docs:
            id = remote_doc["key"]
            if lazy == False or self.document_exists(dbname=dbname, id=id) == True:
                rev = remote_doc["value"]["rev"]
                remote_doc = remote_doc['doc']
                remote_doc.update(docs[ids.index(id)])
                remote_doc = Document(id=id, rev=rev, **remote_doc)
                doc_list.append(remote_doc)
            else:
                self.logger.debug(f"Could not bulk lazy edit document {dbname} {id}")

        doc_list = BulkDocs(docs=doc_list)
        res = self.client.post_bulk_docs(db=dbname, bulk_docs=doc_list).get_result()
        for re in res:
            self.logger.debug(f"Bulk edited document {dbname} {re['id']}")
        self.logger.debug(f"Finished bulk editing {len(doc_list)} documents")


    def documents_get(self, dbname: str, ids: str, lazy: bool = False):
        '''Retrieves multiple documents and returns them.
        
        dbname:  Name of database to get documents from.
        ids: A list of UUIDs of documents to fetch.
        lazy: If true, won't error if any documents don't exist.
        '''
        remote_docs = self.client.post_all_docs(db=dbname, include_docs=True, limit=len(ids), keys=ids).get_result()['rows']
        doc_list = []
        for doc in remote_docs:
            id = doc["key"]
            if lazy == False or self.document_exists(dbname=dbname, id=id) == True:
                self.logger.debug(f"Bulk fetched document {dbname} {id}")
                doc_list.append(doc['doc'])
            else:
                self.logger.debug(f"Could not bulk lazy fetch {dbname} {id}")
        self.logger.debug(f"Finished bulk fetching {len(ids)} documents")
        return doc_list


    def documents_list(self, dbname: str, startkey: str = None, endkey: str = None, limit: int = 25):
        '''Returns a list of all documents in a database. Intensive!
        
        dbname: Name of database to fetch all docs from.
        startkey: If included, document UUID to start fetching from.
        endkey: If included, document UUID to stop fetching at.
        limit: Number of docs to retrieve. Set arbitrary large to fetch all.
        '''
        remote_docs = self.client.post_all_docs(db=dbname, include_docs=True, startkey=startkey, endkey=endkey, limit=limit).get_result()
        docs = []
        for remote_doc in remote_docs['rows']:
            docs.append(remote_doc['doc'])
        self.logger.debug(f"Documents listed from database {dbname}, {startkey if startkey != None else 'START'} to {endkey if endkey != None else 'END'}")
        return docs


    def id_create(self, n: int = 1, length: int = 12, prefix: str = ""):
        '''Generates new UUIDs within Python and returns them.
        
        n: The number of UUIDs to create.
        length: The length of the UUID's hex component.
        prefix: Prefix for the UUID.
        '''
        ids = []
        for _ in range(0, n):
            hexstr = hex(random.randint(0, 16 ** length))[2:]
            id = prefix + "0" * (length - len(hexstr)) + hexstr
            ids.append(id)
        self.logger.debug(f"{n} UUIDs generated by Python")
        return ids


    def id_get(self, n: int = 1, prefix: str = ""):
        '''Retrieves new UUIDs from CouchDB and returns them.
        
        prefix: Prefix to add to the UUID.
        '''
        response = self.client.get_uuids(count=n).get_result()['uuids']
        for index, id in enumerate(response):
            response[index] = prefix+id
        self.logger.debug(f"{n} UUIDs fetched from CouchDB")
        return response


    def index_create(self, dbname: str, name: str, fields: list):
        '''Creates a new MongoDB-style index and returns its id (name).
        
        dbname: Name of database to index.
        name: Name of the index. Also used as design doc's name.
        fields: List of dictionaries of form {"FIELDNAME" : "asc" | "desc"}, defining the index.
        '''
        if (dbname not in list(self.index_cache)): #new database to add indexes to the cache
            self.index_cache[dbname] = []          #create a blank list in the dictionary
                
        if (name not in self.index_cache[dbname]): #new dictionary
            self.index_cache[dbname].append(name)

        index_field_list = []
        for field in fields:
            index_field_list.append(IndexField(**field))
        index_definition = IndexDefinition(fields=index_field_list)
        res = self.client.post_index(db=dbname, index=index_definition, ddoc=name, name=name, type="json").get_result()
        id = res['id'][8:]
        self.logger.debug(f"Created index {dbname} {name}")
        return id


    def index_delete(self, dbname: str, name: str):
        '''Deletes an existing MongoDB-style index.

        dbname: Name of database index is stored in.
        name: Name of the index to be deleted.
        '''
        self.client.delete_index(db=dbname, ddoc=name, type="json", index=name)
        self.logger.debug(f"Deleted index {dbname} {name}")


    def index_exists(self, dbname: str, name: str):
        '''Returns whether or not a MongoDB-style index exists.
        
        dbname: Name of database index is stored in.
        name: Name of the index to be checked.
        '''
        if (dbname in list(self.index_cache)) and (name in self.index_cache[dbname]):
            return True
        try:
            response = self.client.head_design_document(db=dbname, ddoc=name).get_status_code()
            if response == 200:
                self.logger.debug(f"Index {dbname} {name} exists")
                if (dbname not in list(self.index_cache)): #new database to add indexes to the cache
                    self.index_cache[dbname] = []          #create a blank list in the dictionary
                if (name not in self.index_cache[dbname]): #new dictionary
                    self.index_cache[dbname].append(name)
                return True
        except:
            pass
        self.logger.debug(f"Index {dbname} {name} does not exist")
        return False


    def query(self, dbname: str, selector: dict = {}, fields: list = None, sort: list = None, limit: int = 25):
        '''Queries a database using MongoDB-style selectors & indexes.
        
        An index involving the 'sort' fields must exist, otherwise the query will fail.
        For selector operators, see https://docs.mongodb.com/manual/reference/operator/query/

        dbname: Name of database being queried.
        selector: A MongoDB style selector: {"FIELDNAME" : {"OPERATOR": "VALUE"}, ... }. If omitted, returns no documents.
        fields: List of fields to return: ["FIELD1", "FIELD2", ...]. If omitted, returns all fields.
        sort: List defining sort order: [{"FIELD1": "ASC"}, {"FIELD2": "DESC"}, ...]. If omitted, returns in ascending UUID order.
        limit: Number of docs to retrieve. Set arbitrary large to fetch all.
        '''
        res = self.client.post_find(db=dbname, selector=selector, fields=fields, sort=sort, limit=limit).get_result()
        log = f"Queried database {dbname} using {{'selector': {selector}"
        log += f", 'fields': {fields}" if fields != None else ""
        log += f", 'sort': {sort}" if sort != None else ""
        log += f", 'limit': {limit}}}"
        self.logger.debug(log.replace("'",'"'))
        return res['docs']


    def server_check(self):
        '''Returns whether or not the CouchDB server is accessible.'''
        try:
            response = self.client.get_up_information().get_result()
            if response['status'] == 'ok':
                self.logger.debug(f"Database server is accessible.")
                return True
        except:
            pass
        self.logger.debug(f"Database server is not accessible.")
        return False


    def __del__(self):
        '''Runs when Database object is deleted.'''
        self.logger.debug("Database object destroyed")


# ----------------------------------------------------------------------------

class DEHCDatabase:
    '''A class which handles database transactions in DEHC applications.
    
    This class is specific to DEHC and is the one to import into the apps. 
    Importing the Database class up above should not be necessary.
    
    db: The associated Database object.
    db_list: List of DEHC database names.
    db_items: The name of the items database.
    db_containers: The name of the containers database.
    db_ids: The name of the ids database.
    db_files: The name of the files database.
    db_configs: The name of the configs database.
    db_list: A list of the databases used by the DEHCDatabase object.
    id_len: Length of hex part of document UUIDs used in the database.
    limit: Max number of documents to return from _list and _query methods.
    logger: The logger object used for logging.
    schema: Dictionary describing objects and fields in the database.
    schema_path: Path to .json file containing database schema.
    '''

    def __init__(self, *, config: str, level: str = "NOTSET", namespace: str = "dehc", quickstart: bool = False, schema: str = "db_schema.json"):
        '''Constructs a DEHCDatabase object.

        config: Path to .json file containing database server credentials.
        level: Minimum level of logging messages to report; "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL", "NONE".
        namespace: A name to prefix all CouchDB databases with.
        quickstart: Creates databases and loads schema automatically.
        schema: Path to .json file containing database schema, if required.
        '''
        self.logger = ml.get(name="DEHCDatabase", level=level)
        self.logger.debug("DEHCDatabase object instantiated")
        self.db = Database(config=config, level=level)

        self.namespace = namespace
        self.db_items = self.namespace+"-items"
        self.db_containers = self.namespace+"-containers"
        self.db_ids = self.namespace+"-ids"
        self.db_files = self.namespace+"-files"
        self.db_configs = self.namespace+"-configs"
        self.db_list = [self.db_items, self.db_containers, self.db_ids, self.db_files, self.db_configs]
        self.logger.debug(f"Using namespace {namespace}")

        self.id_len = 12
        self.limit = 1000000

        self.schema = {}
        self.schema_path = schema
        if quickstart == True:
            self.logger.debug(f"Performing quickstart")
            self.databases_create(lazy=True)
            self.schema_load(schema=self.schema_path, forcelocal=True)
            self.schema_save()
            self.index_prepare()
            self.logger.debug(f"Completed quickstart")


    def databases_create(self, lazy: bool = False):
        '''Creates DEHC databases.
        
        lazy: If true, won't error if databases already exist.
        '''
        self.logger.debug(f"Creating DEHC databases")
        for db in self.db_list:
            if lazy == False or self.db.database_exists(db) == False:
                self.db.database_create(db)
        self.logger.debug(f"Done creating DEHC databases")


    def databases_clear(self, lazy: bool = False):
        '''Removes all files from DEHC databases.
        
        lazy: If true, won't error if database doesn't exist.
        '''
        self.logger.debug(f"Emptying DEHC databases")
        for db in self.db_list:
            if lazy == False or self.db.database_exists(db) == True:
                items = self.db.documents_list(dbname=db, limit=self.limit)
                items = [item["_id"] for item in items]
                self.db.documents_delete(dbname=db, ids=items)
        self.logger.debug(f"Done emptying DEHC databases")

    
    def databases_delete(self, lazy: bool = False):
        '''Deletes DEHC databases.
        
        lazy: If true, won't error if databases don't exist.
        '''
        self.logger.debug(f"Dropping DEHC databases")
        for db in self.db_list:
            if lazy == False or self.db.database_exists(db) == True:
                self.db.database_delete(db)
        self.logger.debug(f"Done dropping DEHC databases")


    def container_add(self, container: str, item: str, lazy: bool = False):
        '''Puts an item in a container.
        
        container: The UUID of the container.
        item: The UUID of the item.
        lazy: If true, won't error if item already in container.
        '''
        self.logger.debug(f"Adding {item} to {container}")
        idc = container+"/"+item
        if lazy == False or self.db.document_exists(dbname=self.db_containers, id=idc) == False:
            doc = {"container": container, "child": item}
            self.db.document_create(dbname=self.db_containers, doc=doc, id=idc)
        self.logger.debug(f"Done adding {item} to {container}")
        return idc


    def container_adds(self, container: str, items: list):
        '''Puts multiple items in a container.
        
        container: The UUID of the container.
        items: The UUIDs of the items.
        '''
        self.logger.debug(f"Adding {len(items)} items to {container}")
        ids_list = [container+"/"+item for item in items]
        docs_list = [{"container": container, "child": item} for item in items]
        self.db.documents_create(dbname=self.db_containers, ids=ids_list, docs=docs_list)
        self.logger.debug(f"Done adding {len(items)} items to {container}")
        return ids_list


    def container_children(self, container: str, cat: list = None, result: str = "ITEM", limit: int = None):
        '''Returns flat list, listing items contained by a container.

        container: Container to return containing items of.
        cat: If included, only returns children of these categories.
        result: "ITEM" to return item ids, "CON" to return container ids, "DOC" to return item documents.
        fast: If true, the function only returns the first child (by UUID) instead of all children.
        '''
        self.logger.debug(f"Finding children of {container}")
        limit = limit if limit != None else self.limit
        selector = {'container': {'$eq': container}}
        fields = ['_id', 'child']
        sort = [{'container': 'asc'}, {'child': 'asc'}]
        query = self.containers_query(selector=selector, fields=fields, sort=sort, limit=limit)
        if result == "CON":
            children = [row['_id'] for row in query if cat == None or self.id_cat(row['child']) in cat]
        elif result == "ITEM" or result == "DOC":
            children = [row['child'] for row in query if cat == None or self.id_cat(row['child']) in cat]
            if result == "DOC":
                children = self.db.documents_get(dbname=self.db_items, ids=children)
        else:
            raise ValueError("result should be one of ITEM, CON or DOC")
        self.logger.debug(f"Done finding children of {container}")
        return children


    def container_children_all(self, container: str, cat: list = None, result: str = "ITEM"):
        '''Returns flat list, listing items contained by a container and its sub-containers, recursively.

        container: Container to return containing items of.
        cat: If included, only returns children of these categories.
        result: "ITEM" to return item ids, "CON" to return container ids, "DOC" to return item documents.
        '''
        self.logger.debug(f"Finding all children and sub-children of {container}")
        children = self.containers_children_all(containers=[container], cat=cat, result=result)
        self.logger.debug(f"Done finding all children and sub-children of {container}")
        return children


    def container_children_all_dict(self, container: str, cat: list = None):
        '''Returns nested dictionary, listing items contained by a container and all sub-containers, recursively.
    
        container: Container to return containing items of.
        cat: If included, only returns children of these categories.
        '''
        self.logger.debug(f"Finding all children and sub-children of {container}")
        children = self.containers_children_all_dict(containers=[container], cat=cat)
        self.logger.debug(f"Done finding all children and sub-children of {container}")
        return children


    def container_children_dict(self, container: str, cat: list = None):
        '''Returns dictionary, listing items contained by a container.

        container: Container to return containing items of.
        cat: If included, only returns children of these categories.
        '''
        children = {container: self.container_children(container=container, cat=cat)}
        return children


    def container_exists(self, container: str, item: str):
        '''Returns whether or not a container-item relationship exists.
        
        container: The UUID of container to check.
        item: The UUID of item to check.
        '''
        self.logger.debug(f"Checking if {item} is in {container}")
        idc = container+"/"+item
        result = self.db.document_exists(dbname=self.db_containers, id=idc)
        self.logger.debug(f"Done checking if {item} is in {container}")
        return result


    def container_move(self, from_con: str, to_con: str, item: str, lazy: bool = False):
        '''Moves an item from one container to another.
        
        from_con: The UUID of the container the item is leaving.
        to_con: The UUID of the container the item is entering.
        item: The UUID of the item.
        lazy: If true, won't error if from_con doesn't exist, or to_con already exists.
        '''
        self.logger.debug(f"Moving {item} from {from_con} to {to_con}")
        self.container_add(container=to_con, item=item, lazy=lazy)
        self.container_remove(container=from_con, item=item, lazy=lazy)
        self.logger.debug(f"Done moving {item} from {from_con} to {to_con}")


    def container_moves(self, from_con: str, to_con: str, items: list, lazy: bool = False):
        '''Moves multiple items from one container to another.
        
        from_con: The UUID of the container the item is leaving.
        to_con: The UUID of the container the item is entering.
        items: The UUIDs of the items.
        lazy: If true, won't error if from_con doesn't exist, or to_con already exists.
        '''
        self.logger.debug(f"Moving {len(items)} items from {from_con} to {to_con}")
        self.container_adds(container=to_con, items=items)
        self.container_removes(container=from_con, items=items, lazy=lazy)
        self.logger.debug(f"Done moving {len(items)} items from {from_con} to {to_con}")


    def container_remove(self, container: str, item: str, lazy: bool = False):
        '''Removes an item from a container.
        
        container: The UUID of the container.
        item: The UUID of the item.
        lazy: If true, won't error if container or child doesn't exist.
        '''
        self.logger.debug(f"Removing {item} from {container}")
        id = container+"/"+item
        self.db.document_delete(dbname=self.db_containers, id=id, lazy=lazy)
        self.logger.debug(f"Done removing {item} from {container}")


    def container_removes(self, container: str, items: list, lazy: bool = False):
        '''Removes multiple items from a container.
        
        container: The UUID of the container.
        items: The UUIDs of the items.
        lazy: If true, won't error if container or child doesn't exist.
        '''
        self.logger.debug(f"Removing {len(items)} items from {container}")
        ids = [container+"/"+item for item in items]
        self.db.documents_delete(dbname=self.db_containers, ids=ids, lazy=lazy)
        self.logger.debug(f"Done removing {len(items)} items from {container}")


    def containers_children(self, containers: list, cat: list = None, result: str = "ITEM"):
        '''Returns flat list, listing items contained by multiple containers.

        containers: Containers to return containing items of.
        cat: If included, only returns children of these categories.
        result: "ITEM" to return item ids, "CON" to return container ids, "DOC" to return item documents.
        '''
        self.logger.debug(f"Finding children of {len(containers)} containers")
        selector = {'container': {'$in': containers}}
        fields = ['_id', 'child']
        sort = [{'container': 'asc'}, {'child': 'asc'}]
        query = self.containers_query(selector=selector, fields=fields, sort=sort)
        if result == "CON":
            children = [row['_id'] for row in query if cat == None or self.id_cat(row['child']) in cat]
            children = list(dict.fromkeys(children))
        elif result == "ITEM" or result == "DOC":
            children = [row['child'] for row in query if cat == None or self.id_cat(row['child']) in cat]
            children = list(dict.fromkeys(children))
            if result == "DOC":
                children = self.db.documents_get(dbname=self.db_items, ids=children)
        else:
            raise ValueError("result should be one of ITEM, CON or DOC")
        self.logger.debug(f"Done finding children of {len(containers)} containers")
        return children


    def containers_children_all(self, containers: str, cat: list = None, result: str = "ITEM"):
        '''Returns flat list, listing items contained by some containers and all sub-containers, recursively.

        containers: Containers to return containing items of.
        cat: If included, only returns children of these categories.
        result: "ITEM" to return item ids, "CON" to return container ids, "DOC" to return item documents.
        '''
        self.logger.debug(f"Finding all children and sub-children of {len(containers)} containers")
        children = []
        current_containers = containers
        while True:
            ids = self.containers_children(containers=current_containers, result="ITEM")
            if len(ids) > 0:
                children += self.containers_children(containers=current_containers, result=result, cat=cat)
                current_containers = ids
            else:
                break
        self.logger.debug(f"Done finding all children and sub-children of {len(containers)} containers")
        return children


    def containers_children_all_dict(self, containers: list, cat: list = None):
        '''Returns nested dictionary, listing items contained by multiple containers and all sub-containers, recursively.
    
        containers: Containers to return containing items of.
        cat: If included, only returns children of these categories.
        '''
        results = self.containers_children_dict(containers=containers)
        for container in containers:
            result = results[container]
            if len(result) > 0:
                result = self.containers_children_all_dict(containers=result, cat=cat)
            results[container] = result
        if cat != None:
            results_c = results.copy()
            for result in results_c:
                if len(results[result]) == 0 and self.id_cat(result) not in cat:
                    del results[result]
        return results


    def containers_children_dict(self, containers: list, cat: list = None):
        '''Returns dictionary of lists, listing items contained by multiple containers.

        containers: Containers to return containing items of.
        cat: If included, only returns children of these categories.
        '''
        self.logger.debug(f"Finding children of {len(containers)} containers")
        selector = {'container': {'$in': containers}}
        fields = ['_id', 'container', 'child']
        sort = [{'container': 'asc'}, {'child': 'asc'}]
        query = self.containers_query(selector=selector, fields=fields, sort=sort)
        children = {container: [] for container in containers} 
        for row in query:
            child = row['child']
            if cat == None or self.id_cat(child) in cat:
                children[row['container']].append(child)
        self.logger.debug(f"Done finding children of {len(containers)} containers")
        return children


    def containers_list(self):
        '''Retrieves every doc from container database. Intensive!'''
        self.logger.debug(f"Retrieving all containers")
        docs = self.db.documents_list(dbname=self.db_containers, limit=self.limit)
        self.logger.debug(f"Done retrieving all containers")
        return docs


    def containers_query(self, selector: dict = {}, fields: list = None, sort: list = None, limit: int = None):
        '''Queries the container database and returns the results.

        For selector operators, see https://docs.mongodb.com/manual/reference/operator/query/

        selector = A MongoDB style selector: {"FIELDNAME" : {"OPERATOR": "VALUE"}, ... }. If omitted, returns all items.
        fields = List of fields to return: ["FIELD1", "FIELD2", ...]. If omitted, returns all fields.
        sort = List defining sort order: [{"FIELD1": "ASC"}, {"FIELD2": "DESC"}, ...]. If omitted, returns in ascending UUID order.
        limit = If specified, overrides the internally defined limit of for how many rows can be returned.
        '''
        self.logger.debug(f"Querying the containers database")
        limit = limit if limit != None else self.limit
        if sort != None:
            index_name = "idx"
            for field in sort:
                key = next(iter(field.keys()))
                index_name += f"-{key}"
            if self.db.index_exists(dbname=self.db_containers, name=index_name) == False:
                self.db.index_create(dbname=self.db_containers, name=index_name, fields=sort)
        res = self.db.query(dbname=self.db_containers, selector=selector, fields=fields, sort=sort, limit=limit)
        self.logger.debug(f"Done querying the containers database")
        return res


    def id_cat(self, id: str):
        '''Takes a database id and returns its category.
        
        id: The UUID to extract the category of.
        '''
        cat, *_ = id.split("/")
        return cat


    def ids_edit(self, item: str, ids: list):
        '''Edits what physical IDs are associated with an item.
        
        item: The item to edit the physical IDs of.
        ids: A list of strings, consisting of all physical IDs associated with an item.
        '''
        self.logger.debug(f"Editing physical IDs of {item}")
        old_ids = set(self.ids_get(item=item))
        new_ids = set(ids)
        ids_to_create = list(new_ids - old_ids)
        ids_to_delete = list(old_ids - new_ids)
        if len(ids_to_create) > 0:
            docs_create = [{"item": item, "physid": physid} for physid in ids_to_create]
            ids_create = [f"{item}/{physid}" for physid in ids_to_create]
            self.db.documents_create(dbname=self.db_ids, docs=docs_create, ids=ids_create)
        if len(ids_to_delete) > 0:
            ids_delete = [f"{item}/{physid}" for physid in ids_to_delete]
            self.db.documents_delete(dbname=self.db_ids, ids=ids_delete, lazy=True)
        self.logger.debug(f"Done editing physical IDs of {item}")


    def ids_find(self, physid: str):
        '''Finds the items associated with a physical ID, and returns their database IDs.
        
        physid: The physical ID to search against.
        '''
        self.logger.debug(f"Finding item with physical ID of {physid}")
        res = self.db.query(dbname=self.db_ids, selector={'physid': {'$eq': physid}}, fields=['item'], sort=[{'physid': 'asc'}], limit=self.limit)
        self.logger.debug(f"Done finding item with physical ID of {physid}")
        return [row['item'] for row in res]


    def ids_get(self, item: str):
        '''Fetches all physical IDs associated with an item.
        
        item: The item to get the physical IDs of.
        '''
        self.logger.debug(f"Finding physical IDs associated with {item}")
        res = self.db.query(dbname=self.db_ids, selector={'item': {'$eq': item}}, fields=['physid'], sort=[{'item': 'asc'}], limit=self.limit)
        self.logger.debug(f"Done finding physical IDs associated with {item}")
        return [row['physid'] for row in res]


    def index_prepare(self):
        '''Prepares certain known indexes used by database queries.'''
        self.logger.debug(f"Preparing indexes")
        if self.db.index_exists(dbname=self.db_ids, name="idx-item") == False:
            self.db.index_create(dbname=self.db_ids, name="idx-item", fields=[{'item': 'asc'}])
        if self.db.index_exists(dbname=self.db_ids, name="idx-physid") == False:
            self.db.index_create(dbname=self.db_ids, name="idx-physid", fields=[{'physid': 'asc'}])
        self.logger.debug(f"Done preparing indexes")


    def item_create(self, cat: str, doc: dict):
        '''Creates new item in items database, returns id.
        
        cat: The item's category.
        doc: The item's data: {"field": "value", ...}
        '''
        id, = self.db.id_create(length=self.id_len, prefix=cat+"/")
        self.logger.debug(f"Creating new item {id}")
        doc['category'] = cat
        if 'flags' not in doc:
            doc['flags'] = []
        self.db.document_create(dbname=self.db_items, doc=doc, id=id)
        self.logger.debug(f"Done creating new item {id}")
        return id


    def item_delete(self, id: str, all: bool = True, recur: bool = False, lazy: bool = False):
        '''Deletes item from items database.
        
        id: The UUID of item to delete.
        all: If true, also deletes item's container and file docs.
        recur: If true, also deletes all children the item contains.
        lazy: If true, won't error if document doesn't exist.
        '''
        self.logger.debug(f"Deleting item {id}")
        self.db.document_delete(dbname=self.db_items, id=id, lazy=lazy)
        if recur == True:
            self.logger.debug(f"Also deleting all children of {id}")
            all_children = self.container_children_all(container=id, result="ITEM")
            self.items_delete(ids=all_children, all=all, recur=False, lazy=True)
        if all == True:
            self.logger.debug(f"Also deleting all associated documents of {id}")
            children = self.container_children(container=id, result="CON")
            parents = self.item_parents(item=id, result="CON")
            self.db.documents_delete(dbname=self.db_containers, ids=children+parents, lazy=lazy)
            #TODO: Delete associated file (photo) too
        self.logger.debug(f"Done deleting item {id}")


    def item_edit(self, id: str, data: dict, lazy: bool = False):
        '''Edits item in items database.
        
        id: The UUID of item to edit.
        data: Dictionary of fields+values to adjust.
        lazy: If true, won't error if document doesn't exist.
        '''
        self.logger.debug(f"Editing item {id}")
        self.db.document_edit(dbname=self.db_items, id=id, doc=data, lazy=lazy)
        self.logger.debug(f"Done editing item {id}")


    def item_exists(self, id: str):
        '''Returns whether or not an item exists.
        
        id: The UUID of item to check.
        '''
        result = self.db.document_exists(dbname=self.db_items, id=id)
        return result


    def item_get(self, id: str, fields: list = None, lazy: bool = False):
        '''Retrieves item from items database.
        
        id: The UUID of item to retrieve.
        fields: If included, only returns listed fields.
        lazy: If true, won't error if document doesn't exist.
        '''
        self.logger.debug(f"Fetching item {id}")
        doc = self.db.document_get(dbname=self.db_items, id=id, lazy=lazy)
        if fields != None:
            doc = {field: doc.get(field, "") for field in fields}
        self.logger.debug(f"Done fetching item {id}")
        return doc


    def item_parents(self, item: str, cat: list = None, result: str = "ITEM"):
        '''Returns flat list, listing items containing an item.

        item: Item to return containing containers of.
        cat: If included, only returns parents of these categories.
        result: "ITEM" to return item ids, "CON" to return container ids, "DOC" to return item documents.
        '''
        self.logger.debug(f"Finding parents of {item}")
        selector = {'child': {'$eq': item}}
        fields = ['_id', 'container']
        sort = [{'child': 'asc'}, {'container': 'asc'}]
        query = self.containers_query(selector=selector, fields=fields, sort=sort)
        if result == "CON":
            parents = [row['_id'] for row in query if cat == None or self.id_cat(row['container']) in cat]
        elif result == "ITEM" or result == "DOC":
            parents = [row['container'] for row in query if cat == None or self.id_cat(row['container']) in cat]
            if result == "DOC":
                parents = self.db.documents_get(dbname=self.db_items, ids=parents)
        else:
            raise ValueError("result should be one of ITEM, CON or DOC")
        self.logger.debug(f"Done finding parents of {item}")
        return parents


    def item_parents_all(self, item: str, cat: list = None, result: str = "ITEM"):
        '''Returns flat list, listing all items containing an item, recursively.

        item: Item to return containing containers of.
        cat: If included, only returns parents of these categories.
        result: "ITEM" to return item ids, "CON" to return container ids, "DOC" to return item documents.
        '''
        self.logger.debug(f"Finding all parents and grandparents of {item}")
        parents = self.items_parents_all(items=[item], cat=cat, result=result)
        self.logger.debug(f"Done finding all parents and grandparents of {item}")
        return parents


    def item_parents_all_dict(self, item: str, cat: list = None):
        '''Returns nested dictionary, listing all items containing an item, recursively.
        
        item: Item to return containing containers of.
        cat: If included, only returns parents of these categories.
        '''
        self.logger.debug(f"Finding all parents and grandparents of {item}")
        parents = self.items_parents_all_dict(items=[item], cat=cat)
        self.logger.debug(f"Done finding all parents and grandparents of {item}")
        return parents


    def item_parents_dict(self, item: str, cat: list = None):
        '''Returns dictionary, listing items containing an item.

        item: Item to return containing containers of.
        cat: If included, only returns parents of these categories.
        '''
        parents = {item: self.item_parents(item=item, cat=cat)}
        return parents


    def items_create(self, cat: str, docs: list):
        '''Creates multiple new items at once, returns ids.
        
        cat: The items' category.
        docs: The items' data: [{"field": "value", ...}, {"field": "value", ...}, ...]
        '''
        ids = self.db.id_create(n=len(docs), length=self.id_len, prefix=cat+"/")
        self.logger.debug(f"Creating {len(ids)} new items")
        new_docs = []
        for doc in docs:
            doc_c = doc.copy()
            doc_c['category'] = cat
            if 'flags' not in doc:
                doc['flags'] = []
            new_docs.append(doc_c)
        self.db.documents_create(dbname=self.db_items, docs=new_docs, ids=ids)
        self.logger.debug(f"Done creating {len(ids)} new items")
        return ids


    def items_delete(self, ids: list, all: bool = True, recur: bool = False, lazy: bool = False):
        '''Deletes multiple items at once, returns ids.
        
        ids: The UUIDs of items to delete.
        all: If true, also deletes items' container and file docs.
        lazy: If true, won't error if document doesn't exist.
        '''
        self.logger.debug(f"Deleting {len(ids)} items")
        self.db.documents_delete(dbname=self.db_items, ids=ids, lazy=lazy)
        if recur == True:
            self.logger.debug(f"Also deleting {len(ids)} items children")
            all_children = self.containers_children(containers=ids, result="ITEM")
            self.items_delete(ids=all_children, all=all, recur=False, lazy=True)
        if all == True:
            self.logger.debug(f"Also deleting {len(ids)} items associated documents")
            children = self.containers_children(containers=ids, result="CON")
            parents = self.items_parents(items=ids, result="CON")
            self.db.documents_delete(dbname=self.db_containers, ids=children+parents, lazy=lazy)
        self.logger.debug(f"Done deleting {len(ids)} items")


    def items_edit(self, ids: list, data: list, lazy: bool = False):
        '''Edits multiple items at once.
        
        ids: The UUID of item to edit.
        data: Dictionary of fields+values to adjust.
        lazy: If true, won't error if document doesn't exist.
        '''
        self.logger.debug(f"Editing {len(ids)} items")
        self.db.documents_edit(dbname=self.db_items, ids=ids, docs=data, lazy=lazy)
        self.logger.debug(f"Done editing {len(ids)} items")


    def items_get(self, ids: list, fields: list = None, lazy: bool = False):
        '''Retrieves multiple items at once.
        
        ids: The UUIDs of items to retrieve.
        fields: If included, only returns listed fields.
        lazy: If true, won't error if any documents don't exist.
        '''
        self.logger.debug(f"Fetching {len(ids)} items")
        docs = self.db.documents_get(dbname=self.db_items, ids=ids, lazy=lazy)
        if fields != None:
            new_docs = []
            for doc in docs:
                doc = {field: doc.get(field, "") for field in fields}
                new_docs.append(doc)
            docs = new_docs
        self.logger.debug(f"Done fetching {len(ids)} items")
        return docs


    def items_list(self, cat: str = None, fields: list = None):
        '''Retrieves every item in a category from items database. Intensive!
        
        cat: Category to return. If omitted, returns all categories.
        fields: If included, only returns listed fields.
        '''
        self.logger.debug(f"Fetching all items{f' of category {cat}' if cat != None else ''}")
        if cat == None:
            startkey = None
            endkey = None
        else:
            startkey = cat+"/"+self.id_len*"0"
            endkey = cat+"/"+self.id_len*"f"
        docs = self.db.documents_list(dbname=self.db_items, startkey=startkey, endkey=endkey, limit=self.limit)
        if fields != None:
            new_docs = []
            for doc in docs:
                new_doc = {field: doc.get(field, "") for field in fields}
                new_docs.append(new_doc)
            self.logger.debug(f"Done fetching all items{f' of category {cat}' if cat != None else ''}")
            return new_docs
        else:
            self.logger.debug(f"Done fetching all items{f' of category {cat}' if cat != None else ''}")
            return docs


    def items_parents(self, items: list, cat: list = None, result: str = "ITEM"):
        '''Returns flat list, listing items containing one of multiple items.

        items: Items to return containing containers of.
        cat: If included, only returns parents of these categories.
        result: "ITEM" to return item ids, "CON" to return container ids, "DOC" to return item documents.
        '''
        self.logger.debug(f"Finding parents of {len(items)} items")
        selector = {'child': {'$in': items}}
        fields = ['_id', 'container']
        sort = [{'child': 'asc'}, {'container': 'asc'}]
        query = self.containers_query(selector=selector, fields=fields, sort=sort)
        if result == "CON":
            parents = [row['_id'] for row in query if cat == None or self.id_cat(row['container']) in cat]
            parents = list(dict.fromkeys(parents))
        elif result == "ITEM" or result == "DOC":
            parents = [row['container'] for row in query if cat == None or self.id_cat(row['container']) in cat]
            parents = list(dict.fromkeys(parents))
            if result == "DOC":
                parents = self.db.documents_get(dbname=self.db_items, ids=parents)
        else:
            raise ValueError("result should be one of ITEM, CON or DOC")
        self.logger.debug(f"Done finding parents of {len(items)} items")
        return parents


    def items_parents_all(self, items: str, cat: list = None, result: str = "ITEM"):
        '''Returns flat list, listing all items containing one of multiple items, recursively.
        
        items: Items to return containing containers of.
        cat: If included, only returns parents of these categories.
        result: "ITEM" to return item ids, "CON" to return container ids, "DOC" to return item documents.
        '''
        self.logger.debug(f"Finding all parents and grandparents of {len(items)} items")
        parents = []
        current_containers = items
        while True:
            ids = self.items_parents(items=current_containers, result="ITEM")
            if len(ids) > 0:
                parents += self.items_parents(items=current_containers, result=result, cat=cat)
                current_containers = ids
            else:
                break
        self.logger.debug(f"Done finding all parents and grandparents of {len(items)} items")
        return parents


    def items_parents_all_dict(self, items: str, cat: list = None):
        '''Returns nested dictionary, listing all items containing one of multiple items, recursively.
        
        items: Items to return containing containers of.
        cat: If included, only returns parents of these categories.
        '''
        results = self.items_parents_dict(items=items)
        for item in items:
            result = results[item]
            if len(result) > 0:
                result = self.items_parents_all_dict(items=result, cat=cat)
            results[item] = result
        if cat != None:
            results_c = results.copy()
            for result in results_c:
                if len(results[result]) == 0 and self.id_cat(result) not in cat:
                    del results[result]
        return results


    def items_parents_dict(self, items: list, cat: list = None):
        '''Returns nested dictionary, listing items containing one of multiple items.

        items: Items to return containing containers of.
        cat: If included, only returns parents of these categories.
        '''
        self.logger.debug(f"Finding parents of {len(items)} items")
        selector = {'child': {'$in': items}}
        fields = ['_id', 'container', 'child']
        sort = [{'child': 'asc'}, {'container': 'asc'}]
        query = self.containers_query(selector=selector, fields=fields, sort=sort)
        parents = {item: [] for item in items}
        for row in query:
            parent = row['container']
            if cat == None or self.id_cat(parent) in cat:
                parents[row['child']].append(parent)
        self.logger.debug(f"Done finding parents of {len(items)} items")
        return parents


    def items_query(self, cat: str = None, selector: dict = {}, fields: list = None, sort: list = None):
        '''Queries the item database and returns the results.

        For selector operators, see: https://docs.mongodb.com/manual/reference/operator/query/

        cat = Category to query. If omitted, checks all categories.
        selector = A MongoDB style selector: {"FIELDNAME" : {"OPERATOR": "VALUE"}, ... }. If omitted, returns all items.
        fields = List of fields to return: ["FIELD1", "FIELD2", ...]. If omitted, returns all fields.
        sort = List defining sort order: [{"FIELD1": "ASC"}, {"FIELD2": "DESC"}, ...]. If omitted, returns in ascending UUID order.
        '''
        self.logger.debug(f"Querying the items database")
        if cat != None:
            selector['category'] = {"$eq": cat}
        else:
            selector['category'] = {"$ne": ""}
        if sort != None:
            index_name = "idx"
            for field in sort:
                key = next(iter(field.keys()))
                index_name += f"-{key}"
            if self.db.index_exists(dbname=self.db_items, name=index_name) == False:
                self.db.index_create(dbname=self.db_items, name=index_name, fields=[{"category": "asc"}]+sort)
        res = self.db.query(dbname=self.db_items, selector=selector, fields=fields, sort=sort, limit=self.limit)
        self.logger.debug(f"Done querying the items database")
        return res


    def photo_delete(self, item: str):
        '''Deletes the photo, associated with an item, from the database.
        
        item: The item to delete the photo of.
        '''
        self.logger.debug(f"Deleting photo of {item}")
        name = "photo-"+item
        if self.db.document_exists(dbname=self.db_files, id=name) == True:
            self.db.document_delete(dbname=self.db_files, id=name)
        self.logger.debug(f"Done deleting photo of {item}")


    def photo_load_base64(self, item: str):
        '''Loads the photo, associated with an item, from the database, leaves it in base64
        
        item: The item to load the photo of.
        '''
        self.logger.debug(f"Fetching photo of {item} as base64")
        name = "photo-"+item
        if self.db.document_exists(dbname="files", id=name) == True:
            self.logger.debug(f"Done fetching photo of {item} as base64")
            return self.db.document_get(dbname="files", id=name)['photo']            
        else:
            self.logger.debug(f"Done fetching photo of {item} as base64")
            return None


    def photo_load(self, item: str):
        '''Loads the photo, associated with an item, from the database.
        
        item: The item to load the photo of.
        '''
        self.logger.debug(f"Fetching photo of {item}")
        name = "photo-"+item
        if self.db.document_exists(dbname=self.db_files, id=name) == True:
            doc = self.db.document_get(dbname=self.db_files, id=name)
            img = base64.b64decode(doc['photo'])
            buffer = io.BytesIO(img)
            self.logger.debug(f"Done fetching photo of {item}")
            return Image.open(buffer)
        else:
            self.logger.debug(f"Done fetching photo of {item}")
            return None


    def photo_save(self, item: str, img: Image):
        '''Saves a photo, associated with an item, to the database.

        Photos are saved as JPEG using base64 encoding.
        
        item: The item the photo is associated with.
        img: The PIL object to save to the database.
        '''
        self.logger.debug(f"Saving photo of {item}")
        buffer = io.BytesIO()
        img.save(buffer, format="JPEG")
        data = base64.b64encode(buffer.getvalue()).decode('utf-8')
        name = "photo-"+item
        if self.db.document_exists(dbname=self.db_files, id=name) == True:
            self.db.document_edit(dbname=self.db_files, doc={"item": item, "photo": data}, id=name)
        else:
            self.db.document_create(dbname=self.db_files, doc={"item": item, "photo": data}, id=name)
        self.logger.debug(f"Done saving photo of {item}")


    def schema_cats(self):
        '''Returns the list of categories present in the schema.'''
        cats = list(self.schema.keys())
        return cats


    def schema_fields(self, *, cat: str = None, id: str = None):
        '''Returns the list of fields for a particular kind of item.

        Only cat OR id needs to be provided. If both, cat is used.

        cat: Category of item to recieve fields of.
        id: ID of item to recieve fields of.
        '''
        if cat == None:
            cat = self.id_cat(id=id)
        fields = list(self.schema[cat]["fields"].keys())
        return fields


    def schema_flags(self, *, cat: str = None, id: str = None):
        '''Returns the list of flags for a particular kind of item.

        Only cat OR id needs to be provided. If both, cat is used.

        cat: Category of item to recieve flags of.
        id: ID of item to recieve flags of.
        '''
        if cat == None:
            cat = self.id_cat(id=id)
        flags = self.schema[cat].get("flags", [])
        return flags


    def schema_keys(self, *, cat: str = None, id: str = None):
        '''Returns the list of key fields for a particular kind of item.

        Only cat OR id needs to be provided. If both, cat is used.
        
        cat: Category of item to recieve key fields of.
        id: ID of item to recieve key fields of.
        '''
        if cat == None:
            cat = self.id_cat(id=id)
        keys = self.schema[cat]["keys"]
        return keys


    def schema_load(self, schema: str = None, forcelocal: bool = False):
        '''Loads database schema into memory.

        Will look for doc "schema" in db "items" first, then locally.
        
        schema: Path to local .json file containing database schema.
        forcelocal: If true, uses local schema over one stored in the database.
        '''
        self.logger.debug(f"Loading database schema")
        if forcelocal == False and self.db.document_exists(dbname=self.db_configs, id="schema") == True:
            self.logger.debug(f"Loading database schema from database")
            loaded_schema = self.db.document_get(dbname=self.db_configs, id="schema")
        else:
            self.logger.debug(f"Loading database schema from {schema}")
            with open(schema, "r") as f:
                loaded_schema = json.loads(f.read())
        for key, value in self.schema.items():
            if "/" in key:
                raise ValueError("Category names cannot contain / chars.")
                # ...because they're used in UUIDs to split category from number
            if "category" in value["fields"]:
                raise ValueError("category can't be a field name.")
                # ...because it's reserved by app for identifying item types
        self.schema = loaded_schema
        self.logger.debug(f"Done loading database schema")


    def schema_name(self, *, cat: str = None, id: str = None):
        '''Returns the first field of a particular kind of item.
        
        Only cat OR id needs to be provided. If both, cat is used.

        cat: Category of item to recieve fields of.
        id: ID of item to recieve fields of.
        '''
        field, *_ = self.schema_fields(cat=cat, id=id)
        return field


    def schema_save(self):
        '''Saves database schema to the database.'''
        self.logger.debug(f"Saving database schema")
        if self.db.document_exists(dbname=self.db_configs, id="schema"):
            self.db.document_edit(dbname=self.db_configs, doc=self.schema, id="schema")
        else:
            self.db.document_create(dbname=self.db_configs, doc=self.schema, id="schema")
        self.logger.debug(f"Done saving database schema")


    def schema_schema(self, *, cat: str = None, id: str = None):
        '''Returns the schema of a particular kind of item.
        
        Only cat OR id needs to be provided. If both, cat is used.

        cat: Category of item to recieve fields of.
        id: ID of item to recieve fields of.
        '''
        if cat == None:
            cat = self.id_cat(id=id)
        schema = self.schema[cat]["fields"]
        return schema


    def schema_sums(self):
        '''Returns all of the summable fields within the entire schema.'''
        summables = []
        for cat, schema in self.schema.items():
            for field, info in schema['fields'].items():
                if info['type'] == "sum" or info['type'] == "count":
                    summables.append(field)
        return list(dict.fromkeys(summables))


    def __del__(self):
        '''Runs when DEHCDatabase object is deleted.'''
        self.logger.debug("DEHCDatabase object destroyed")


# ----------------------------------------------------------------------------